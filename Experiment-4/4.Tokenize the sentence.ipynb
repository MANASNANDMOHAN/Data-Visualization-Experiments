{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0526be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a program in python to tokenize the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a04fd139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Manas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "sentence = \"The quick brown fox jumped over the lazy dog.\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e5c9946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tushar', 'is', 'an', 'intelligent', 'and', 'naughty', 'boy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Manas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "sentence = \"Tushar is an intelligent and naughty boy\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f5b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "punkt is a module in the Natural Language Toolkit (nltk) that contains data required for tokenization. \n",
    "It contains pre-trained models for tokenization of various languages including English.\n",
    "When you download the punkt module using nltk.download('punkt'), you are downloading the required data for tokenization. \n",
    "Once you have downloaded the module, you can use it to tokenize text into words and sentences.\n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b8364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demonstrating tokenization using libraries such as NLTK or spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a5e9b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.5.3-cp39-cp39-win_amd64.whl (12.2 MB)\n",
      "     ---------------------------------------- 0.0/12.2 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.7/12.2 MB 15.0 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 1.9/12.2 MB 23.6 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 3.3/12.2 MB 26.1 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 4.6/12.2 MB 26.4 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 5.2/12.2 MB 28.0 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 5.2/12.2 MB 28.0 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 5.2/12.2 MB 28.0 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 5.2/12.2 MB 28.0 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.3/12.2 MB 15.5 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.3/12.2 MB 15.5 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.3/12.2 MB 15.5 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.3/12.2 MB 15.5 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.3/12.2 MB 15.5 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 6.3/12.2 MB 9.9 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 7.7/12.2 MB 11.2 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.3/12.2 MB 12.6 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 10.2/12.2 MB 13.0 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 10.5/12.2 MB 13.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 10.5/12.2 MB 13.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 10.5/12.2 MB 13.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 11.0/12.2 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.2/12.2 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.2/12.2 MB 10.4 MB/s eta 0:00:00\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.6-cp39-cp39-win_amd64.whl (482 kB)\n",
      "     ---------------------------------------- 0.0/482.8 kB ? eta -:--:--\n",
      "     ------------------------------------- 482.8/482.8 kB 29.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\manas\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Collecting pathy>=0.10.0\n",
      "  Downloading pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "     ---------------------------------------- 0.0/48.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 48.9/48.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\manas\\anaconda3\\lib\\site-packages (from spacy) (2.29.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 0.0/181.6 kB ? eta -:--:--\n",
      "     ------------------------------------- 181.6/181.6 kB 11.4 MB/s eta 0:00:00\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp39-cp39-win_amd64.whl (18 kB)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\manas\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\manas\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.7-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 2.2/2.2 MB 67.8 MB/s eta 0:00:00\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp39-cp39-win_amd64.whl (96 kB)\n",
      "     ---------------------------------------- 0.0/96.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 96.8/96.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\manas\\anaconda3\\lib\\site-packages (from spacy) (23.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\manas\\anaconda3\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Downloading thinc-8.1.10-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.5/1.5 MB 31.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\manas\\anaconda3\\lib\\site-packages (from spacy) (66.0.0)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\manas\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manas\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\manas\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\manas\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\manas\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp39-cp39-win_amd64.whl (7.0 MB)\n",
      "     ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "     --------- ------------------------------ 1.6/7.0 MB 52.5 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 2.1/7.0 MB 45.2 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 2.1/7.0 MB 45.2 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 2.1/7.0 MB 45.2 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 2.1/7.0 MB 45.2 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 3.0/7.0 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 3.8/7.0 MB 12.2 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 3.8/7.0 MB 12.2 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 3.8/7.0 MB 12.2 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 3.8/7.0 MB 12.2 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 4.7/7.0 MB 9.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 6.4/7.0 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.0/7.0 MB 11.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\manas\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\manas\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\manas\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, pydantic, murmurhash, langcodes, catalogue, blis, typer, srsly, preshed, pathy, confection, thinc, spacy\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.0.4 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.7 spacy-3.5.3 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.10 typer-0.7.0 wasabi-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650ff0ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the English language model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Input text\u001b[39;00m\n\u001b[0;32m      7\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe quick brown fox jumped over the lazy dog.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     38\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py:449\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Input text\n",
    "text = \"The quick brown fox jumped over the lazy dog.\"\n",
    "\n",
    "# Apply tokenization using spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the tokens\n",
    "for token in doc:\n",
    "    print(token.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38006a9f",
   "metadata": {},
   "source": [
    "Error solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be177baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "To resolve this issue, you can follow these steps to install the 'en_core_web_sm' model:\n",
    "\n",
    "Open a terminal or command prompt.\n",
    "\n",
    "Run the following command to install the model using pip:\n",
    "\n",
    "Copy code\n",
    "python -m spacy download en_core_web_sm\n",
    "Make sure you have an active internet connection as the command will download the model data from the internet.\n",
    "\n",
    "After the installation is complete, try running your code again. It should be able to load the 'en_core_web_sm' model without any errors.\n",
    "\n",
    "If you still encounter issues after installing the model, make sure you have the correct Python environment \n",
    "and the necessary permissions to install packages.\n",
    "\n",
    "Once the model is successfully installed, you should be able to load it using spacy.load(\"en_core_web_sm\") \n",
    "and perform tokenization and other NLP tasks with spaCy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
