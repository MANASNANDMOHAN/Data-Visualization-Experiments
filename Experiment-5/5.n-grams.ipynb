{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb497e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a program in python to generate n-grams from the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05be0b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The', 'quick', 'brown')\n",
      "('quick', 'brown', 'fox')\n",
      "('brown', 'fox', 'jumps')\n",
      "('fox', 'jumps', 'over')\n",
      "('jumps', 'over', 'the')\n",
      "('over', 'the', 'lazy')\n",
      "('the', 'lazy', 'dog')\n",
      "('lazy', 'dog', '.')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# define the input text\n",
    "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# set the value of n for n-grams\n",
    "n = 3\n",
    "\n",
    "# tokenize the text\n",
    "tokens = nltk.word_tokenize(input_text)\n",
    "\n",
    "# generate n-grams\n",
    "n_grams = list(ngrams(tokens, n))\n",
    "\n",
    "# print the n-grams\n",
    "for gram in n_grams:\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f1e157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I', 'love', 'travelling')\n",
      "('love', 'travelling', 'and')\n",
      "('travelling', 'and', 'playing')\n",
      "('and', 'playing', 'valorant')\n",
      "('playing', 'valorant', 'with')\n",
      "('valorant', 'with', 'my')\n",
      "('with', 'my', 'friends')\n",
      "('my', 'friends', 'and')\n",
      "('friends', 'and', 'brothers')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# define the input text\n",
    "input_text = \"I love travelling and playing valorant with my friends and brothers\"\n",
    "\n",
    "# set the value of n for n-grams\n",
    "n = 3\n",
    "\n",
    "# tokenize the text\n",
    "tokens = nltk.word_tokenize(input_text)\n",
    "\n",
    "# generate n-grams\n",
    "n_grams = list(ngrams(tokens, n))\n",
    "\n",
    "# print the n-grams\n",
    "for gram in n_grams:\n",
    "    print(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e699d",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "In natural language processing (NLP), an n-gram is a contiguous sequence of n items from a given sample of text or speech. \n",
    "Typically, the items in question are words, but they can also be characters or other linguistic units.\n",
    "\n",
    "For example, in the sentence \"The quick brown fox jumps over the lazy dog,\" some possible n-grams would be:\n",
    "\n",
    "Unigrams (n=1): The, quick, brown, fox, jumps, over, the, lazy, dog\n",
    "Bigrams (n=2): The quick, quick brown, brown fox, fox jumps, jumps over, over the, the lazy, lazy dog\n",
    "Trigrams (n=3): The quick brown, quick brown fox, brown fox jumps, fox jumps over, jumps over the, over the lazy, the lazy dog\n",
    "N-grams are often used in NLP for tasks such as language modeling, where the goal is to predict the likelihood of a given sequence of words. \n",
    "They can also be used in machine translation, speech recognition, and other applications.\n",
    "############################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
